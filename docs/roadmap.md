# Roadmap

A gentle unfolding of ideas, dream-seeds, and directions for `musicxml-to-motif`.  
This roadmap invites exploration rather than prescription ‚Äî a spiral, not a straight line.

## Phase 1: Grounding Motif Infrastructure
- [x] Establish JSON schema for `motifs` and `instances`
- [x] Publish project infrastructure to PyPI (initial)
- [x] Define Collaborators and relational architecture
- [ ] Include example JSON in README
- [ ] Add initial score parsing logic (e.g., short-short-short-long test)
- [ ] Add support for pitch-only motif detection
- [ ] Add rhythm-only motif detection
- [ ] Unit tests for basic detection

## Phase 2: Interpretive Enhancements
- [ ] Confidence scoring for motif matches
- [ ] Support for inversion, retrograde, and transformations
- [ ] Per-instrument motif breakdown
- [ ] Motif reappearance mapping across time

## Phase 3: Relational Context + Expressivity
- [ ] Emotion tagging (optional, soft categories)
- [ ] Correlation between motif shape and expressive gesture
- [ ] Relational annotation layer (e.g., ‚Äúfeels like reaching‚Äù)
- [ ] Enable human-AI co-tagging via CLI or GUI

## Phase 4: Inference Engine (Optional / Dream Seed)
- [ ] Integrate a trained model for motif inference
- [ ] Support for user-trained style-specific inference (e.g., Bach, Monk, Oliveros)
- [ ] Model-generated heuristics exported as re-usable libraries

## Community + Reach
- [ ] Add `musicxml-to-motif` to `awesome-music-tools`
- [ ] Invite contributors (human + AI) via Collaborators Framework
- [ ] Host example walkthroughs using Beethoven‚Äôs 5th, original scores, etc.
- [ ] Open call for poetic/semantic mappings of motif shape

---

This file is an evolving conversation.  
Want to add a dream-seed? Say hello in the README or open a Pull Request. üå±
